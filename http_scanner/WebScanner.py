import re
import os
import sys
import urllib3
import requests
import subprocess
from concurrent.futures import ThreadPoolExecutor


class WebScanner:
    def __init__(self, wordlist_path, user_pass_file, url_file, output_sqlmap_file, output_file, ip=None):
        """
        Initialize the WebScanner instance with the necessary parameters for scanning.

        :param wordlist_path: Path to the wordlist file.
        :param user_pass_file: Path to the file containing user credentials.
        :param url_file: Name of the file to store URLs.
        :param output_sqlmap_file: Output file name for sqlmap results.
        :param output_file: General output file for scan results.
        :param ip: Optional IP address of the target.
        :param domain: Optional domain name of the target.
        """
        ip_regex = re.compile(r'^(?:\d{1,3}\.){3}\d{1,3}$')
        self.host = ip  
        self.domain = not bool(ip and ip_regex.match(ip))
    
        requests.packages.urllib3.disable_warnings()
        self.ensure_directory_exists(self.host)
        self.wordlist_path = wordlist_path
        self.user_pass_file = user_pass_file
        self.url_file = os.path.join(self.host, url_file)
        self.output_file = os.path.join(self.host, output_file)
        self.output_sqlmap_file = os.path.join(self.host, output_sqlmap_file)

    @staticmethod
    def ensure_directory_exists(directory):
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"Created directory: {directory}")


    def execute_command(self, command, output_path=None):
        """
        Execute a shell command, print outputs in real-time with special characters handled,
        and optionally write them to a specified file.
        
        :param command: The command to execute.
        :param output_path: Optional path to a file where output will be written.
        :return: List of output lines from the command.
        """
        process = subprocess.Popen(
            command,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )

        output_lines = []

        file = open(output_path, "w") if output_path else None

        try:
            while True:
                line = process.stdout.readline()
                if line:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                    if file:
                        file.write(line)
                    output_lines.append(line.strip())
                if process.poll() is not None:
                    if not line:
                        break

            for line in process.stdout:
                sys.stdout.write(line)
                sys.stdout.flush()
                if file:
                    file.write(line)
                output_lines.append(line.strip())

        finally:
            if file:
                file.close()

        return output_lines


    def run(self):
        if not os.path.exists(self.url_file):
            open(
                self.url_file, "w"
            ).close()  # Crée le fichier urls.txt s'il n'existe pas

        self.execute_sublist3r()
        self.execute_paramspider()
        self.process_urls()
        self.run_dalfox()
        self.prepare_and_run_sqlmap()

        if self.check_host():
            found_directories = self.dir_buster()
            self.fetch_urls_content(found_directories)

    def check_host(self):
        protocols = ["http", "https"]
        reachable = False

        for protocol in protocols:
            url = f"{protocol}://{self.host}"
            print(f"Vérification de la disponibilité de l'adresse {url}...")
            try:
                response = requests.head(url, timeout=10, verify=False)
                if response:
                    print(
                        f"L'adresse {url} est active et répond avec le code {response.status_code}."
                    )
                    reachable = True
            except requests.ConnectionError as e:
                print(f"Impossible de se connecter à l'adresse {url}: {e}")
            except requests.Timeout:
                print(f"La requête vers l'adresse {url} a expiré.")
            except requests.RequestException as e:
                print(f"Erreur lors de la requête vers {url}: {e}")

        if reachable:
            print("L'adresse IP est accessible.")
            return True
        else:
            print(
                f"L'adresse IP {self.host} ne répond sur aucun des protocoles (HTTP ou HTTPS)."
            )
            print("L'IP n'est pas accessible.")
            return False

    def dir_buster(self):
        output_file_path = os.path.join(self.host, "gobuster_output.txt")
        command = f"gobuster dir -u http://{self.host} -w {self.wordlist_path} -b '403,404,301'"
        print("Démarrage de l'exécution de Gobuster...")
        output_lines = self.execute_command(command, output_file_path)
        if output_lines:
            print("Gobuster a terminé son exécution.")
            return self.parse_gobuster_output(output_lines)
        else:
            print("Gobuster n'a pas pu s'exécuter correctement.")
            return []

    def parse_gobuster_output(self, output_lines):
        found_directories = []
        try:
            for line in output_lines:
                clean_line = re.sub(r"\x1b\[2K", "", line).strip()
                if clean_line:
                    match = re.search(r"^/([^ ]+)", clean_line)
                    if match:
                        directory = match.group(1)
                        found_directories.append(f"/{directory}")
        except Exception as e:
            print(f"Erreur lors du traitement des résultats de Gobuster : {e}")
        return found_directories

    def fetch_urls_content(self, directories):
        try:
            with ThreadPoolExecutor(max_workers=10) as executor:
                executor.map(self.fetch_url_content, directories)
        except Exception as e:
            print(f"Erreur inattendue: {e}")

    def fetch_url_content(self, directory):
        full_url = f"http://{self.host}{directory}"
        try:
            response = requests.get(full_url)
            if response.status_code == 200:
                self.search_and_write_keywords(response.text, directory)
        except requests.RequestException as e:
            print(f"Erreur lors de la requête vers {full_url}: {e}")

    def search_and_write_keywords(self, content, directory):
        patterns = {
            "username": r"username\s*=\s*([^\s,;]+)",
            "password": r"password\s*=\s*([^\s,;]+)",
            "email": r"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})",
        }
        with open(self.output_file, "a") as file:
            for key, pattern in patterns.items():
                for match in re.finditer(pattern, content, re.IGNORECASE):
                    if key == "email":
                        email_user = match.group(1).split("@")[0]
                        file.write(
                            f"Found in {directory}: username derived from email = {email_user}\n"
                        )
                    else:
                        file.write(f"Found in {directory}: {key} = {match.group(1)}\n")

    def process_urls(self):
        try:
            with open(self.url_file, "r") as file:
                urls = file.readlines()
            processed_urls = [url.replace("FUZZ", "{}").strip() for url in urls]
            with open(self.url_file, "w") as file:
                file.writelines(url + "\n" for url in processed_urls)
            print("Les URLs ont été modifiées et enregistrées.")
        except FileNotFoundError:
            print(f"Le fichier {self.url_file} n'a pas été trouvé.")
        except Exception as e:
            print(f"Erreur lors de la modification des URLs : {e}")

    def execute_paramspider(self):
        if self.domain is not None:
            print("Démarrage de l'exécution de ParamSpider...")
            output_file_path = os.path.join(self.host, "paramspider_output.txt")
            command = f"paramspider -d {self.host}"
            self.execute_command(command, output_file_path)
            print("ParamSpider a terminé son exécution.")
        else:
            print("Parampider ignoré (fonctionne seulement avec domaine)...")    

    def execute_sublist3r(self):
        if self.domain is not None:
            print("Démarrage de l'exécution de Sublist3r...")
            command = f"sublist3r -d {self.host} -o {self.host}/result_sublist3r.txt"
            self.execute_command(command)
            print("Sublist3r a terminé son exécution.")
        else:
            print("Sublist3r ignoré (fonctionne seulement avec domaine)...")    

    def run_dalfox(self):
        path = os.path.join("results", f"{self.host}.txt")
        if os.path.exists(path):
            output_file_path = os.path.join(self.host, "dalfox_output.txt")
            print("Démarrage de l'exécution de Dalfox...")
            command = f"dalfox file {path}"
            self.execute_command(command, output_file_path)
            print("Dalfox a terminé son exécution.")
        else:
            print(f"Le fichier {path} n'existe pas.")

    def prepare_and_run_sqlmap(self):
        path = os.path.join("results", f"{self.host}.txt")
        if not os.path.exists(path):
            print(f"Le fichier {path} n'existe pas.")
            return

        try:
            with open(path, "r") as file:
                urls = [
                    url.strip().replace("FUZZ", "*") + "\n"
                    for url in file
                    if url.strip()
                ]

            if not urls:
                print("Aucune URL valide à traiter pour SQLMap.")
                return

            with open(self.output_sqlmap_file, "w") as file:
                file.writelines(urls)
            print("URLs prêtes pour sqlmap ont été enregistrées.")
        except Exception as e:
            print(f"Erreur lors de la préparation des URLs pour SQLMap : {e}")
            return

        sqlmap_output_file = os.path.join(self.host, "sqlmap_output.txt")
        if os.path.getsize(self.output_sqlmap_file) > 0:
            print("Démarrage de l'exécution de SQLMap...")
            command = f"sqlmap -m {self.output_sqlmap_file} --batch --output-dir={sqlmap_output_file}"
            self.execute_command(command)
        else:
            print("Le fichier des URLs pour SQLMap est vide.")


if __name__ == "__main__":
    scanner = WebScanner(
        domain="balgogan-kerago.eu",
        wordlist_path="wordlists/directory-list-2.3-medium.txt",
        user_pass_file="wordlists/user_pass.txt",
        url_file="urls.txt",
        output_sqlmap_file="output_sqlmap.txt",
        output_file="scan_results.txt",
    )
    scanner.run()
